%%
% The BIThesis Template for Graduate Thesis
%
% Copyright 2020-2023 Yang Yating, BITNP
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   https://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Feng Kaiyu.
\chapter{Introduction}

\label{chap:intro}
%\section{研究的目的和意义 Purpose and Significance of This Research}

With digitalization, networking, and artificial intelligence technologies developing rapidly, global cyberspace is expanding at an unprecedented pace. Software has permeated every layer of government administration, social services, industrial control, and personal life. However, the rapid iteration and large-scale deployment of software not only reveals that software brings convenience, but also implies that the software has also been a prime target for cyberattacks. Software security issues which pose a serious threat to national security, economic development, and even social stability have been more and more prominent, with the severe condition that malicious software emerges as one of weapons which is the most active, covert, and damaging in cyberattacks.

The Security Navigator 2024 report reveals the fact that the global cybersecurity condition continued to be severe in 2023. Orange Cyberdefense's CyberSOC detected 129,395 cyberattack incidents, which represents an increase of 30\% compared to last year. Among these, security analysts confirmed 25,076 incidents that are dominated by hacker attacks, privilege abuse, and malicious software attacks result in actual threats. The report highlighted that the number of global ransomware victims reached a historic high in 2023, which surges 46\% compared to last year. Critical infrastructure sectors such as government agencies, energy, power, and healthcare became primary targets for Advanced Persistent Threat (APT) attacks, which are characterized as being highly targeted, long-dormant, and highly destructive.\cite{securitynavigator2024}

The Annual Cybersecurity Threat Report 2024, which is released by Qianxin Threat Intelligence Center, analyzed the global cybersecurity landscape in February 2025. In 2024, APT attacks, ransomware, and black-gray industry activities continued to increase. Multiple malicious groups such as Kimsuky and Lazarus persistently attacked critical software systems and infrastructure. In addition, intricate connections among ransomware groups made cyberattacks more covert and hazardous, while malware variants and vulnerability utilization increasingly became the key method of attack. The report also indicated that black-gray industry groups such as Silver Fox Trojan and Bigpanzi exposed severe threats to software security and network security, especially in the facet of software vulnerability utilization and malicious code propagation.

Meanwhile, attacker tactics have consistently evolved from early simple viruses and worms to intelligent malicious samples which focus on multi-stage attacking chains, automated generation, and evasion mechanisms. Especially with the support of AI technologies, malicious software exhibits "self-learning, self-adaptation, and self-mutation" intelligent features, which make traditional malware detection methods—such as trait comparison, rule matching, and static scanning—increasingly ineffective\cite{chen2018study, ren2021matching, lipp2022empirical}. According to statistics, the detection rate of existing static techniques for novel malicious samples has dropped below 60\%, while adversarial samples which are generated from benign software by simple disturbances can increase the false positive rate of major popular detection models to over 80\%. This phenomenon exposes tremendous deficiencies in current malware detection systems against intelligent adversarial threats.

Faced with this imbalance between attack and defense, researchers have begun to simulate attacker perspectives by artificial intelligence techniques like Reinforcement Learning, generating adversarial samples to enhance detection system robustness. However, most current adversarial generation methods still exist notable limitations, such as targeting only specific detection models, employing simplistic disturbance methods, and inadequately considering sample semantic consistency and behavioral concealment, which makes researchers fail to simulate "dynamic adversarial processes" in complex attack scenarios\cite{yu2022natural, ilahi2021challenges, labaca2021aimed,standen2025adversarial}. Moreover, existing methods are insufficient in the consideration of disturbances costs and sample transferability, which hinders the application, scalability, and practicality of generated samples.

Although various methods get significant achievements, current research still faces several challenges. On the one hand, some methods rely excessively on model structure or gradient information, which makes them struggle to adapt to real black-box scenarios. On the other hand, while ensuring misguidance, adversarial examples often reduce sample executability or semantic plausibility, particularly for data that has highly semantic meaning, such as code and text. Furthermore, existing studies generally focus on attacking single models, limiting evasion effects against joint defense or multi-model integrated malware detection systems.

Therefore, how to effectively attack multiple detection systems while ensuring sample functional integrity and semantic consistency has become a crucial research direction of current research. Meanwhile, designing universal, light, and highly transferable attack frameworks is also a key challenge for future research.

This study focuses on the "Reinforcement Learning-based multi-dimensional adversarial malware generation method" and aims to overcome the difficulties of adversarial sample generation methods, such as model transferability, disturbance accuracy, and evasion capability by constructing an intelligent adversarial framework with practicality and versatility. The specific research contents are listed as follows:

\begin{enumerate} [label=\arabic*)] 
\item Malware Disturbance Dimension Modeling and Design: To solve the limitation that traditional adversarial sample generation methods mainly rely on static operations that are insufficient for having intervention at the behavioral layer of samples such as byte insertion or section padding, this research models disturbance of original malware from three dimensions—structural layer, instruction layer, and behavioral layer, systematically establishing a controllable disturbance operation space. Structural layer disturbance includes operations that modify sample format without affecting executability, such as section renaming, section resorting, and section padding. Instruction layer disturbance mainly contains slight code level operations like inserting no-operation (NOP) instructions or replacing equivalent instructions. Behavioral layer disturbance is comprised by operations that subtly modify malware dynamic behavior, such as replacing system calls or disturbing configuration paths. This multi-dimensional design aims to enhance disturbance diversity and combining abilities, providing abundant operational choices for following strategy learning.

\item Introducing Benign Sample Feature Disturbance Mechanism: Different from traditional methods using random noise or invalid padding bytes, this study innovatively introduces feature byte sequences that are extracted from real benign software samples as disturbance byte sources. This method enhances the "benign concealment effect" of adversarial samples and increases the misjudgment rate of malware detection systems. By constructing a benign byte repository and through encoding and filtering its semantic information, it prioritizes selecting benign fragments similar to the target sample to embed in the target sample during disturbance, which improves the interpretability and obfuscation capability of generated samples.

\item Reinforcement Learning Environment Modeling and Strategy Optimization Design: This research regards the adversarial sample generation process as a sequential problem about making decisions in Reinforcement Learning. The state space is defined as the disturbance history, static features, and dynamic features of the current malware sample. The action space is composed of the predefined disturbance operation set. The reward function considers multiple dimensions indicators such as evasion success rate, disturbance cost, and execution effectiveness. To enhance sequential modeling ability, a Long Short-Term Memory (LSTM) network is introduced as a section of the policy network to model the temporal dependencies between perturbation sequences. Besides, the Proximal Policy Optimization (PPO) algorithm is being used to improve the stability and training efficiency of strategy learning, which alleviates the training difficulties in high dimensional sparse reward scenarios.

\item Dynamic Reward Mechanism Design and Generalization Ability Optimization: To enhance the generated sample practicality and make the generated sample have the ability to attack multiple platforms, this research designs a dynamic reward function driven by target detector feedback and disturbance cost to constrain training resources and disturbance cost.
\end{enumerate}

Furthermore, multiple heterogeneous detectors are introduced to construct a multi-model training environment, and enhance strategy generalization, which ensures that generated samples can not only evade the target training model but also have high transferability to confront the detection of unknown or evolving systems.



