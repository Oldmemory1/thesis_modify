%\chapter{基于强化学习的对抗性恶意软件生成方法研究方案 Research Solution for Adversarial Malware Generation Technology Based on Reinforcement Learning}

%本章将具体地介绍本文提出的对抗样本生成方法的详细设计过程和实现原理，主要包括扰动方法的构建，奖励函数策略的设计，模型的具体结构。

%This chapter will specifically introduce the detailed design process and implementation principles of the adversarial sample generation method proposed in this research, which mainly includes disturbance methods' construction, the reward function strategies' design, and the model's specific structure.

%\section{多维度扰动方法的构建 Multidimensional Disturbance Methods' Construction}

%本文利用lief库、IDA pro对二进制可执行样本进行批量处理。LIEF（Library to Instrument Executable Formats）是一个开源的库，用于处理ELF、PE和Mach-O格式的可执行文件。它可以解析和修改二进制文件的头部信息、节区、符号和动态链接。LIEF适用于静态分析、重命名符号、插入代码和文件格式转换等任务。LIEF可以提取二进制可执行文件的结构，以及提供各个结构的操作接口。

%This research batch processes binary executable samples using the LIEF library and IDA Pro. LIEF (Library to Instrument Executable Formats) is an open-source library for processing executable files in ELF, PE, and Mach-O formats. It can parse and modify header information, sections, symbols, and dynamic linking in binary files. LIEF is applicable to tasks such as static analysis, symbol renaming, code insertion, and file format conversion. LIEF can extract the structure of binary executable files and provide operation interfaces for various components.

%\subsection{结构化扰动方法 Structural Disturbance Methods}

%在恶意软件的对抗性样本生成过程中，结构层面的扰动指的是通过修改文件的内部结构来引入变化，这种变化通常不会影响文件的执行逻辑，但能够有效地逃避传统的检测方法。结构层面的扰动包括但不限于文件的节区、导入符号、动态库、以及压缩/解压缩等操作。

%In the adversarial malware sample generation process, structural level disturbances refer to introducing changes by modifying a file's internal structure. These changes commonly do not affect the file's execution logic but effectively evade traditional detection methods. Structural level disturbances include operations on sections, imported symbols, dynamic libraries, compression, and decompression, but are not limited to these.

%这些扰动主要关注的是通过改变文件结构中的某些元素来达到以下目的：

%These disturbances primarily concentrate on achieving the following purposes by altering certain elements in the file structure:

%增加文件的不可预测性：通过随机化或改变文件的某些部分，使得检测系统很难依赖固定模式进行识别。

%Increasing file unpredictability: By randomizing or changing parts of the file, detection systems hardly identify the file, relying on fixed patterns.

%避开静态分析：静态分析工具通常依赖文件的固定结构特征，如节区（Section）、符号表、导入表等。通过扰动这些结构，可以增加检测的难度。

%Evading static analysis: Static analysis tools often depend on fixed file structural features, such as sections, symbol tables, and import tables. Disturbing these structures increases detection difficulty.

%防止签名匹配：一些恶意软件检测工具依赖于已知恶意样本的特征（如哈希值、节区结构等）进行匹配。通过扰动结构，可以使文件与原始恶意样本在这些特征上产生差异，从而避开检测。

%Avoiding signature matching: Some malware detection tools rely on known signatures, such as values, section structures from malicious samples. Disturbing structures creates differences between the file and the original malicious sample in these signatures, enabling evasion.

%（1）节区（Section）扰动

%(1) Section Disturbance

%在ELF（Executable and Linkable Format）文件中，节区是文件的基本构建单元。它们存储了不同类型的数据（如代码、数据、符号等）。通过对节区内容进行扰动，可以修改文件的行为或使其变得更加复杂。常见的节区扰动方式包括：

%In ELF files, sections are the fundamental units, storing different types of data, such as code, data, symbols. Disturbing section content can modify file behavior or increase its complexity. Common section perturbation methods include:

%节区内容的修改：例如，在现有节区中附加随机数据、将特定节区的数据替换为 benign 数据（如无害的字符串或二进制内容）等。这样可以增加恶意文件的复杂性并避免与已知恶意样本的特征匹配。

%Modifying section content: For example, appending random data to existing sections or replacing data in specific sections with benign data like harmless strings or binary content increases malicious files’ complexity and avoids matching known malicious sample signatures.

%节区重命名：将节区名称修改为常见的名称或随机名称，使得检测工具无法轻易识别文件中的关键节区，如 .text 节区，通常包含程序代码。

%Renaming sections: Changing section names to common or random names makes it harder for detection tools to identify critical sections, especially the .text section that contains program code.

%本文设计的节区扰动如表\ref{tab:4.1}所示。

%The section disturbance design in this paper is listed in Table \ref{tab:4.1}.

%\begin{table}[htbp]
%	\centering
%	\caption{节区扰动类型}\label{tab:4.1}
%	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ccc}
%		\toprule
%		扰动 & 简写 & 效果 \\
%		\midrule
%		section\_append & SA & 向随机选择的节中追加随机数据（可能改变节的内容和熵） \\
%		add\_section\_benign\_data & ASBD & 从 benign 文件中提取整个节，并添加到目标 ELF 中 \\
%		add\_section\_strings & ASS & 生成一个新的节，填充 benign 字符串内容 \\
%		section\_rename & SR & 随机重命名一个节，使用常见节名列表中的名称 \\
%		\bottomrule
%	\end{tabular*}
%\end{table}

%（2）导入符号和库扰动

%(2) Imported Symbol and Library Disturbance

%ELF文件中的导入符号表（dynamic symbol table）包含了程序运行时需要链接的外部函数或库。通过扰动这些符号，可以使恶意软件的行为更加不可预测。例如：

%The dynamic symbol table in ELF files contains external functions or libraries that require runtime linking. Disturbing these symbols can make malware behavior more unpredictable. For example:

%添加恶意符号：将恶意的动态符号（如恶意函数名）添加到文件中，或者通过与良性文件进行符号混合，增加文件的复杂性。

%Adding malicious symbols: Inserting malicious dynamic symbols such as malicious function names into the file or mixing symbols with benign files to increase complexity.

%修改库依赖：修改ELF文件所依赖的动态库，使其依赖于一个不存在或不常见的库，从而打乱传统的静态分析过程。

%Modifying library dependencies: Altering ELF dependency libraries that do not exist or are not common disrupts traditional static analysis processes.

%本文设计的导入符号和库扰动如表\ref{tab:4.2}所示。

%The imported symbol and library disturbances designed in this paper are listed in Table \ref{tab:4.2}.

%\begin{table}[htbp]
%	\centering
%	\caption{导入符号和库扰动}\label{tab:4.2}
%	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ccc}
%		\toprule
%		扰动方法 & 简写 & 效果 \\
%		\midrule
%		add\_imports & AI & 从 benign ELF 文件中添加一个动态符号到目标 ELF 中（如函数导入） \\
%		add\_library & AL & 从 benign ELF 文件中添加一个共享库和其导入函数 \\
%		\bottomrule
%	\end{tabular*}
%\end{table}


%（3）随机数据附加（Overlay）

%(3) Random Data Appending (Overlay)

%Overlay技术通过在文件末尾添加随机数据（通常是无害数据或伪装数据），可以在不改变文件执行流程的情况下修改文件的大小和结构。这种技术常用于恶意软件中以绕过基于签名的检测。常见的技术包括：

%Overlay techniques involve appending random data that is commonly harmless or disguised to the end of a file, altering its size and structure without changing execution logic. This technique is commonly used in malware to evade detection based on signature comparison. Common methods include:

%追加随机字节：将随机的字节序列附加到ELF文件的末尾。此操作不会影响文件的执行逻辑，但可能会改变文件的哈希值，使其避开传统的哈希匹配检测。

%Appending random bytes: Adding random byte sequences to the end of ELF files. This operation does not affect execution logic but may change file hashes, making the file evade traditional detection based on hash comparison.

%追加无害二进制文件内容：从已知的良性文件中提取节区或二进制内容，插入到恶意文件中，以增加文件的复杂度并扰乱静态分析工具的检测。

%Appending benign binary content: Inserting sections or binary content extracted from known benign files into malicious file increases complexity and disrupts static analysis tool detection.

%\begin{table}[htbp]
%	\centering
%	\caption{随机数据附加类型}\label{tab:4.3}
%	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ccc}
%		\toprule
%		扰动方法 & 简写 & 效果 \\
%		\midrule
%		overlay\_append & OA & 在二进制文件的末尾附加随机内容 \\
%		append\_benign\_data\_overlay & ABDO & 追加来自 benign ELF 文件 .text 段的内容 \\
%		append\_benign\_binary\_overlay & ABBO & 直接追加整个 benign ELF 文件内容 \\
%		add\_strings\_to\_overlay & ASTO & 追加来自 benign 字符串文件的内容（UTF-8 编码） \\
%		\bottomrule
%	\end{tabular*}
%\end{table}

%（4）压缩与解压缩（UPX打包与解包）

%(4) Compression and Decompression (UPX Packing and Unpacking)

%压缩恶意文件是另一种常见的扰动技术。通过使用UPX等压缩工具对ELF文件进行压缩，可以隐藏文件的原始结构，并使文件在未经解压时不可执行。这种方法主要有以下特点：

%Compressing malicious files is another common disturbance technique. Compressing ELF files using tools like UPX can hide the original file structure and make the file non-executable without decompression. This approach primarily has the following features:

%压缩：压缩文件可以改变文件的内部结构，使其看起来与原始文件完全不同，从而避开基于特征的检测。

%Compression: Compressed files alter the file's internal structure, making it appear entirely different from the original, thereby evading detection based on features.

%解压缩：压缩的ELF文件在运行时会被解压缩回原始状态，因此需要额外的解压步骤。通过这种方式，恶意软件的行为和文件结构可以被“隐藏”在压缩层后面，增加了反向工程和静态分析的难度。

%Decompression: Compressed ELF files are decompressed to their original state during runtime, requiring an additional decompression step. This method allows malicious software behaviors and file structures to be hidden behind the compression layer, increasing the difficulty of reverse engineering and static analysis.

%\begin{table}[htbp]
%	\centering
%	\caption{压缩加壳类型}\label{tab:4.4}
%	\begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}ccc}
%		\toprule
%		扰动方法 & 简写 & 效果 \\
%		\midrule
%		upx\_pack & UP & 使用 upx 对 ELF 文件进行压缩 \\
%		upx\_unpack & UUP & 使用 upx -d 解压已压缩的 ELF 文件 \\
%		\bottomrule
%	\end{tabular*}
%\end{table}

%（5）Go语言的go-bindata工具包装ELF文件

%(5) go-bindata Toolbox in Go for Packaging ELF Files

%go-bindata是一个Go工具，旨在将二进制文件（如ELF文件、图片、音频文件等）转化为Go源代码中的字节数组。在恶意软件分析领域，通过将ELF文件嵌入到Go程序中，可以有效隐藏ELF文件的实际内容，并增加静态分析和反向工程的难度。具体而言，go\_bindata\_wrapper方法通过将ELF文件转换为Go代码，实现在Go程序中隐藏ELF文件的功能。这种方式使得恶意文件能够避开常规的静态检测和签名匹配工具。

%go-bindata is a Go tool designed to convert binary files, such as ELF files, images, and audio files, into byte arrays within Go source code. In the malware analysis realm, embedding ELF files into Go programs effectively conceals their actual content and increases the difficulty of static analysis and reverse engineering. Specifically, the go\_bindata\_wrapper method converts ELF files into Go code to hide their functionalities in Go programs, which enables malicious files to evade common static detection and signature-matching tools.

%go-bindata工具的作用：go-bindata工具将任何二进制文件（如ELF文件）嵌入到Go源代码中，并生成一个包含文件内容的Go文件。在程序运行时，生成的Go文件将包含文件的字节数组，这些字节数据可以被Go程序读取，并用于恢复原始文件内容。此方法使得ELF文件内容隐藏在Go源代码中，从而增加了恶意软件在反向工程过程中的隐蔽性。

%Function of the go-bindata tool: The go-bindata tool embeds any binary file like ELF files into Go source code, generating a Go file containing the file's content. When the file is executed, this generated Go file includes a byte array that the Go program can read to recover the original file's content. This method hides ELF file content in Go source code, enhancing the concealment of malware during reverse engineering.

%-bindata工具将ELF文件转换为Go源代码，并生成一个Go文件，Go文件中包含该ELF文件的字节数据。通过Go编译器将包含ELF文件字节数据的Go代码编译成最终的Go可执行文件。ELF文件在运行时会被读取并恢复，执行原始文件的操作。

%First, convert the ELF file into Go source code using the go-bindata tool, generating a Go file containing the ELF file's byte data. Then, compile this Go code that contains the ELF byte data into a final Go executable program using the Go compiler. At runtime, the ELF file is read and recovered to execute its original operations.

%通过go-bindata工具，go\_bindata\_wrapper方法为恶意文件提供了一种新的隐蔽方式，将ELF文件嵌入到Go程序中，从而有效地规避静态分析工具和签名匹配的检测。

%Through the go-bindata tool, the go\_bindata\_wrapper method provides a novel concealment approach for malicious files by embedding ELF files into Go programs, thus effectively evading static analysis tools detection and signature matching.

%（6）节头表修改

%(6) Section Header Table Modification

%节头表扰动旨在通过修改二进制文件中的特定元数据或表头信息，从而改变其表象特征，扰乱检测工具或逆向分析过程。这种技术常用于恶意软件分析中的对抗样本生成，目的是使恶意程序绕过传统的反病毒软件或沙箱检测系统，增加分析难度。\ref{tab:4.5}介绍了本文使用的两种节头表扰动方法。

%The target of section header table disturbances is altering the apparent characteristics of binary files by modifying specific metadata or header information, thereby disrupting detection tools or reverse analysis processes. This technique is commonly used in adversarial sample generation for malware analysis, aiming to help malicious programs evade traditional antivirus software or sandbox detection systems and increase analysis difficulty. Figure \ref{tab:4.5} introduces two section header table disturbance methods adopted in this paper.

%\begin{table}[htbp]
%	\centering
%	\caption{节头表扰动类型}\label{tab:4.5}
%	\begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}ccc}
%		\toprule
%		扰动方法 & 简写 & 效果 \\
%		\midrule
%		Remove Debug & RD & 在二进制文件中删除调试信息（用零填充） \\
%		Break Checksum & BC & 在可选标题中删除校验和值（用零填充） \\
%		\bottomrule
%	\end{tabular*}
%\end{table}

%\subsection{指令扰动方法 Instruction Disturbance Methods}

%在本研究中，本文使用强大的反汇编工具 IDA Pro 对 ELF 格式的恶意软件样本进行静态分析与代码提取，为后续的语义保持扰动操作奠定基础。尽管对于剥离符号信息（如符号表、调试信息）的 x86 架构 ELF 可执行文件，难以做到完全精确的反汇编，但现有的高级反汇编器（如 IDA Pro）已可通过多种技术手段对主流编译器生成的代码实现较高覆盖率。这些手段包括：多种反汇编算法的结合使用、对特定代码结构的识别、以及简单的数据流分析等。在处理 ELF 文件时，IDA Pro 通过识别符号信息和程序头表中的节区（如 .text、.plt、.rela.plt 等），能够较准确地定位函数边界，识别控制流，并生成基本块图和函数调用图，帮助提取语义稳定的指令区域进行变换。

%In this research, powerful disassembly tools like IDA Pro are adopted to perform static analysis and code extraction on ELF-format malware samples, establishing a foundation for subsequent disturbance operations that ensure semantics. Although achieving fully precise disassembly remains challenging for stripped symbols like missing symbol tables and debugging information ELF executables on x86 architecture, advanced current disassemblers like IDA Pro can achieve high coverage for code generated from prevalent compilers through combined disassembly algorithms, recognition of specific code structures, and basic data-flow analysis. When processing ELF files, IDA Pro identifies symbol information and sections in the Program Header Table, such as .text, .plt, .rela, and .plt, enabling locating function boundaries accurately, recognizing control flow, and generating basic block graphs and function call graphs. This facilitates the extraction of semantically stable instruction regions for transformation.

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.1}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{IDA 反汇编 CFG 图}\label{fig:4.1}
%\end{figure}


%为确保扰动操作不影响原始程序逻辑，本文首先将反汇编得到的指令转换为一种自定义的中间表示（IR），该表示能记录每条指令的操作码、显式与隐式操作数、寄存器读写关系、以及影响到的标志位等静态语义信息。这种增强表示形式可有效辅助分析控制依赖与数据依赖关系，识别出可安全修改的指令区域。随后，本文实施三种语义保持的扰动技术：指令替换（Instruction Substitution）、指令重排序（Instruction Reordering） 和 寄存器重分配（Register Reallocation）。这三类方法分别从指令级别、顺序层级和寄存器使用层面引入扰动，旨在保持语义不变的前提下实现样本多样性和模型鲁棒性提升。

%To ensure disturbances do not disrupt the original program logic, the disassembled instructions are first transformed into a custom Intermediate Representation (IR). This IR records each instruction's static semantic information, such as opcode, explicit and implicit operands, register read and write relationships, and impacted flag bits, which effectively aids in analyzing control and data dependencies to identify safely modifiable instruction regions. Subsequently, three disturbance techniques—Instruction Substitution, Instruction Reordering, and Register Reallocation—ensure semantics are implemented. These methods respectively introduce disturbances at the instruction level, sequential layer, and register usage level, aiming to enhance sample diversity and model robustness while preserving semantics.

%在变换过程中，所有修改操作均限制在已识别的、无控制依赖冲突的基本块内部，确保程序控制流图（CFG）保持稳定。如果某些变换操作（如指令顺序调整）导致代码地址偏移，本文会同步更新 ELF 文件中的相关重定位信息（如 .rela.text 段），以避免函数调用或跳转地址错误。整个扰动流程针对每个 ELF 文件独立执行，可自动生成多个等价但具有不同语法表现的扰动样本，用于训练或测试阶段的多样化增强，从而有效提升基于静态分析的恶意代码检测系统的鲁棒性。

%During transformation, all modifications are limited to identified basic blocks free of control dependency conflicts, ensuring Program Control Flow Graph (CFG) stability. If transformations like instruction resequencing cause code address shifts, relevant relocation information, such as .rela section and .text section, in the ELF file is synchronously updated to prevent faulty function call and jump address. This process executes per ELF file independently, automatically generating multiple syntactically distinct yet semantically equivalent adversarial samples. These enhance diversity in training and testing phases, effectively improving the robustness of malware detection systems based on static analysis.

%（1） 指令替换（Instruction Substitution）

%(1) Instruction Substitution

%指令替换作为一种二进制代码扰动方法，旨在通过将原始指令替换为等效的指令来扰乱程序的结构，同时保持程序的功能不变。该方法不仅能改变代码的外观，还能增加静态分析和逆向工程的难度。以下是指令替换的具体细节：

%nstruction substitution serves as a binary code disturbance method that alters program structure by replacing original instructions with equivalent ones while preserving program functionality. It not only disrupts code appearance but also increases the difficulty for static analysis and reverse engineering. Details are described as follows:

%等效指令替换：

%Equivalent Instruction Replacement:

%在x86架构中，许多指令有多个等效形式，可以用不同的操作数或指令格式来实现相同的功能。例如：
%add r/m32, r32 可以替换为 add r32, r/m32，这两者在操作数为寄存器时是等效的。

%On x86 architecture, many instructions have multiple equivalent forms, same functionality can be achieved by different operands and instruction forms.For example, “add r/m32, r32” can be replaced with “add r32, r/m32”, these two instructions are equivalent while operands are registers.

%对于逻辑操作，test r/m8, r8 可以与 test r/m8, r/m8 等价。

%For logic operations, “test r/m8, r8” is equivalent to “test r/m8, r/m8”.

%一些算术指令也有多个等效形式，比如 sub r/m32, r32 可以用 neg r/m32 替换（减法可以通过取负来实现）。

%Some arithmetic instructions also have multiple equivalent forms, such as “sub r/m32, r32” can be replaced with “neg r/m32”.

%操作数形式替换指令时，可以改变操作数的形式，而不影响最终的计算结果。例如，mov r32, r/m32 和 mov r/m32, r32 都是等效的操作，但通过改变源和目标操作数的顺序，能够改变指令的字节表示。

%Operand forms can be altered when instructions are replaced, and do not affect ultimate calculation result. For example, “mov r32, r/m32” and “mov r/m32, r32” are equivalent operations, but the instruction byte expression can be altered by changing the sequence of source and target operands.

%不同长度指令某些情况下，可以用长度相同但操作不同的指令替换原始指令，例如：
%inc r32可以替换为 add r32, 1，二者功能相同，但指令长度和编码不同。

%In some circumstances, replacing original instructions with instructions that are the same length but different in operations are permitted.
%For example, “inc r32” can be replaced with “add r32, 1”, these two instructions have same functionality, different instruction length and coding.

%dec r32可以替换为 sub r32, 1，实现同样的效果，增加了代码的复杂性。

%“dec r32” can be replaced with “sub r32, 1”, these two instructions have same effect, but increase code's complexity.

%替换控制流指令：

%Control Flow Instruction Replacement:

%控制流指令（如跳转、条件跳转、调用等）也可以用等效的指令替换。例如：
%jmp label 可以用 call label; pop 来替换，虽然实现了相同的跳转效果，但操作数和指令形式不同。

%Control flow instructions, such as jump, conditional jump, and call, can be replaced with equivalent instructions. For example, “jmp label” can be replaced with “call label; pop”, although two instructions achieve same jump result, but their operands and instruction forms are different.

%je（等于跳转）可以替换为 jne（不等于跳转），并通过适当调整标志位来维持功能一致性。

%“je” can be replaced with “jne” by adjusting the flags properly to maintain functional consistency.

%确保指令长度一致：

%Maintain instruction length consistency:

%由于对于许多stripped二进制文件，增加指令长度可能会导致代码结构破坏，因此在替换过程中要保证每条替换的指令与原指令长度相同。可以通过选择长度一致的等效指令来实现这一点，避免扰乱程序的整体布局。

%Increasing instruction length may cause code structure to be broken in many stripped binary files; thus, it is vital to ensure that each replaced instruction's length should be the same as the original. This can be achieved by selecting equivalent instructions that have the same length, avoiding disrupting the program's overall layout.

%随机化替换的应用方式：

%The application method of randomized replacement:

%在替换指令时，可以根据一定的规则或随机选择等效指令来应用这些替换。替换不一定是对每条指令都应用，而是根据程序的特性和分析结果，选择性地对特定代码块进行替换。这种方法可以确保替换不会影响程序的控制流和逻辑结构，但同时会改变程序的外观，增加静态分析的难度。

%Replacements can be applied according to certain rules or randomized equivalent instruction selection. Replacements may not be applied to each instruction but are selectively applied to specific code blocks relying on program characteristics and analysis results. This method can ensure that replacements do not affect the program's control flow and logic structure but alter the program's appearance, increasing static analysis difficulty.

%通过以上方法，指令替换不仅保持程序功能的完整性，还有效增加了程序的混淆性，使得静态分析工具更难识别程序的真实意图，增加了逆向工程的复杂性。

%Through the methods above, instruction replacements not only maintain the program's complete functionalities but also increase the program's obfuscation, making it harder for static analysis tools to recognize the program's real intention and increasing the complexity of reverse engineering.

%（2）指令重排序（Instruction Reordering）

%(2) Instruction Reordering

%基本块内部指令重排（Intra Basic Block Reordering）：

%Intra Basic Block Reordering:

%在一个基本块（Basic Block）中，若两条或多条指令之间没有数据或控制依赖关系，那么它们的执行顺序就是可以互换的。由于基本块是线性执行的中间代码区域，并且编译器在生成机器码时只是选择了若干等效顺序之一，因此只要保证依赖关系不变，修改指令顺序不会影响程序的功能。

%In a basic block, instructions without data and control dependencies can be reordered without affecting functionality. Since basic blocks are intermediate code areas for linear execution, and the compiler only selects one of equivalent sequences during machine code generation, thus instruction sequence modification does not affect the program's functionality if the dependency relationship remains unchanged.

%本文对目标二进制程序进行反汇编，提取所有基本块。对每个基本块进行依赖分析，识别每条指令的读（use）和写（def）寄存器集。通过检测读后写（RAW）、写后读（WAR）、写后写（WAW）等依赖类型，构建出指令间的有向无环图（DAG）。

%This research disassembles target binaries to extract all basic blocks, then perform dependency analysis on each block, identifying each instruction's use and def register sets, constructing a Directed Acyclic Graph (DAG) among instructions by detecting RAW (Read-After-Write), WAR (Write-After-Read), and WAW (Write-After-Write) dependencies.

%之后，使用拓扑排序枚举该图的合法指令顺序，并从中随机选取一种新的顺序，替代原始顺序。这一方法不会引入新的指令或修改指令操作数，因此保持程序的功能完全不变。它可以扰乱基于指令顺序或特征码的静态分析和检测机制，有效提升样本的多样性。

%Subsequently, this research enumerates legal instruction orders via topological sorting and randomly selects a new order to replace the original. This method can maintain the program's functionality because it does not introduce any new instructions or modify instruction operands. It disrupts static analysis mechanisms relying on instruction order or signatures, enhancing sample diversity.

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.2}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{指令替换示例图}\label{fig:4.2}
%\end{figure}

%寄存器保护代码重排（Reordering of Register Preservation Code）：

%Reordering of Register Preservation Code:

%该方法基于函数调用时保存非易失性寄存器（callee-saved registers）所使用的push和pop指令的顺序是可变的，只要遵循“先进后出”的栈规则即可。即，函数在开头会使用若干push指令保存寄存器，函数结尾使用对应的pop恢复值。因为栈是倒序恢复的，所以只要保持pop顺序与push顺序相反，整个过程的语义就是等效的。

%This method is based on the theory that the sequence of push and pop instructions from callee-saved registers is alterable during function calls, which only need to follow the last-in-first-out (LIFO) stack rule. During function calls, the order of push (callee-saved registers) and corresponding pop instructions can vary if adhering to the last-in-first-out (LIFO) stack rule. Several push instructions are used by the function header to save data in registers, while corresponding pop instructions are used at the end of the function to restore values. Since the stack restores in reverse order, semantics during the entire process will be equivalent to the original if pop sequences are the opposite of push sequences.

%本文在函数的入口和出口识别出完整的寄存器保存/恢复代码段。对这些push和pop指令进行配对，确认其保护的是相同的寄存器，并追踪栈指针（ESP）的变化确保没有中间干扰。然后，对push序列进行重排，并将pop序列同步做相反的重排，确保恢复顺序正确。若push序列中夹杂有其他非保存性指令，也需进行依赖分析，保证重排不会打乱依赖顺序。这种方法对程序语义无影响，但能干扰基于特定pop序列模式的分析方法，提高静态分析、指令特征提取和样本分类的复杂度。

%This research identifies complete register save and restore code segments at the function entry and exit. Then pair push and pop instructions, ensuring that they operate on the same registers and track ESP changes to avoid other interference. Subsequently, reordering the push sequence and applying inverse reordering to pop sequence ensures restore proper sequence. If the push sequence contains other non-preservation instructions, dependency analysis is also essential to ensure that reordering does not disrupt dependency sequence. This method has no impact on the program's semantics but disturbs analysis methods based on specific pop sequence patterns, improving resistance to static analysis, instruction feature extraction, and classification.

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.3}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{指令重构排序示例图}\label{fig:4.3}
%\end{figure}

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.4}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{重构的指令有序无环图}\label{fig:4.4}
%\end{figure}

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.5}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{寄存器保护代码重排序示例图}\label{fig:4.5}
%\end{figure}

%本文首先对二进制程序构建控制流图（CFG），并对每个基本块进行寄存器活跃性分析，获取每条指令的寄存器use（使用）与def（定义）集合。接着迭代计算每条指令的活跃输入集（in）与输出集（out），识别每个寄存器的活跃区域。在确保无冲突的前提下，随机选择两个不重叠活跃区的寄存器对，将其在汇编中的使用位置进行替换。指令修改时，通过变更ModR/M字节（必要时SIB字节）实现重映射，避免使用esp等特殊寄存器，并对隐式使用寄存器的指令进行过滤。为保证调用一致性，还需结合调用约定信息约束某些寄存器的使用。

%First, this method constructs the CFG for the binary program and performs register liveness analysis on each basic block to determine each instruction's register use and def sets. Second, this method iteratively computes each instruction's active in and out sets to identify live ranges in each register. On the premise that there is no conflict, two register pairs with non-overlapping live ranges are randomly selected, and then their usage positions are swapped in assembly. During instruction modification, modifying via ModR/M bytes (and SIB bytes if necessary) achieve remapping, avoiding special registers like ESP, filtering instructions with implicit register usage. To ensure call consistency, calling convention information is combined to constrain certain registers.

%这一方法不会引入新指令或修改操作数值，仅在机器码层面更换寄存器编号，因此程序行为保持完全一致。该技术能有效打乱静态分析工具基于寄存器使用模式或特征序列的识别策略，从而提升样本的对抗性与多样性。

%This technique does not introduce any new instructions or change operand values, modifying only register encodings at the machine-code level. It disrupts static analysis tools based on register usage patterns or feature sequences recognition strategies, enhancing sample adversariality and diversity.

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=0.75\textwidth]{figures/4.6}
%	% \caption[这里的文字将会显示在 listoffigure 中]{这里的文字将会显示在正文中}
%	\caption{寄存器重分配示例图}\label{fig:4.6}
%\end{figure}

%\subsection{动态行为扰动方法 Dynamic Behavior Disturbance Methods}

%在恶意软件检测领域，动态分析技术是当前主流手段之一，尤其在处理未知样本或多态变种时具有明显优势。其基本原理是通过在受控执行环境（如沙箱、虚拟机、内存监控器）中运行目标程序，记录其在运行过程中所触发的系统调用、行为路径、内存修改、网络通信等信息，以此识别潜在的恶意行为。然而，这一技术在实际部署中往往存在时间资源受限的问题。为了兼顾效率与成本，动态分析系统通常仅为每个样本分配数秒到几十秒的执行时间窗口。对于某些攻击行为触发依赖于条件判断、用户交互的恶意样本而言，这一固定的分析时间窗显然存在被规避的可能性。

%In the malware detection realm, dynamic analysis technology is one of the currently prevalent approaches, demonstrating clear advantages when handling unknown or polymorphic variants. Its fundamental principle involves running target programs in controlled execution environments, such as sandboxes, virtual machines, and memory monitors, recording triggered system calls, behavioral paths, memory modifications, network communications, and other runtime information to identify potential malicious behaviors. However, this technology often faces time and resource constraints during deployment. To balance efficiency and cost, dynamic analysis systems commonly allocate only a few seconds to dozens of seconds of execution time to each sample. For malware whose attack behaviors depend on conditional triggers or user interaction, this fixed analysis window presents a probability of being evaded.

%基于此观察，本文设计了一种动态扰动方法，核心思想是引入“时间延迟”机制，使恶意代码在样本启动后故意等待一段时间再执行核心逻辑，从而躲避沙箱的行为分析窗口。其主要实现方式是通过在程序入口点或关键路径中插入延迟逻辑（如 nanosleep系统调用），使恶意样本在运行初期不表现任何异常行为，从而骗过基于行为特征的检测系统。

%Based on this observation, this research designs a dynamic disturbance method whose central mechanism is introducing "time-delay", deliberately waiting for a period after startup before executing core logic, making the malicious code evade the behavioral analysis window of sandboxes. This is primarily implemented by inserting delay logic like the nanosleep system call at program entry points or critical paths, ensuring that the malware exhibits no abnormal behavior during the initial run phase and thus bypasses detection systems based on behavioral features.

%具体而言，该方法在程序入口\_start 中插入一段系统调用延迟逻辑，构造一个 timespec结构体设置延迟时间（如60秒），并通过nanosleep系统调用实现挂起效果。在延迟期间，样本处于休眠状态，不触发任何系统调用，也不进行内存读写、网络通信等可疑操作。由于大多数沙箱系统会在执行时间到达后强制中止进程，此时还未触发的恶意行为链将完全无法被观测到。这样，恶意样本即使具有明显的破坏性，也可能因“未表现行为”而被误判为正常程序。

%Specifically, this method inserts system call delay logic at the \_start entry point. It constructs a timespec structure to set the delay duration and invokes the nanosleep system call to induce suspension. During this delay, the sample remains dormant, triggering no system calls, memory reads and writes, network communications, or other suspicious activities. As most sandbox systems forcibly terminate processes after exceeding the execution time limit, the un-triggered malicious behavioral chain remains entirely unobserved. Consequently, even obviously destructive malware may be misclassified as benign due to "absence of malicious behavior."

%该策略可归类为一种“动态行为隐藏技术”，其本质在于对行为时间的扰动，从时间维度上对抗行为检测系统。这类技术的优势在于实现成本低、兼容性好且对原有逻辑无破坏性，能够与其他扰动策略（如控制流平坦化、代码插桩、系统调用替换）联合使用，从而形成更强的检测对抗能力。

%This strategy can be classified as a "dynamic behavior concealment technique." Its essence is using timing disturbance behavior to counter detection systems temporally. Its advantages include low implementation cost, high compatibility, and non-destructive impact on original logic. It can also be combined with other disturbance strategies, such as control-flow flattening, code instrumentation, and system call replacement to form more robust evasion capabilities.

%值得注意的是，虽然该策略在现实场景中具有较强的隐蔽性，但其也可能被高级动态检测系统检测到。例如某些系统会使用加速执行技术（如时间跳跃模拟）、分析行为间歇性、或启用用户交互模拟等手段来破除延迟机制。因此，未来仍需结合其他对抗策略，共同提升样本的免杀能力和对抗鲁棒性。

%It is notable that this technique may still be detected by advanced dynamic analysis systems while having effective concealment in real scenarios. For example, some systems may employ execution acceleration techniques such as time-jump simulation, behavioral intermittency analysis, and user-interaction simulation, to counter delays. Therefore, future work should integrate other adversarial strategies to jointly enhance evasion and robustness.
%\begin{algorithm}[htbp]
%	\caption{使用可执行段填充空间进行 ELF 动态插入算法}
%\KwIn{目标 ELF 二进制文件路径 \texttt{input\_elf}，载荷二进制代码路径 \texttt{code\_bin}，输出 ELF 路径 \texttt{output\_elf}}
%	\KwOut{一个已被感染的 ELF 文件，其中插入了载荷代码}
%	Read the input ELF file \texttt{input\_elf} into memory \texttt{hdr}\;
%	Read the payload binary code \texttt{code\_bin} into memory \texttt{code}\;
%	Validate ELF magic number and ensure it is a 64-bit ELF\;
%	Check if the ELF architecture is x86-64\;
%	\ForEach{program header \texttt{phdr} in \texttt{hdr}}{
%		\If{\texttt{phdr} is executable (has \texttt{PF\_X} flag)}{
%			Find the last section \texttt{last\_sec} within \texttt{phdr}\;
%			Compute the available padding size \texttt{pad\_size} after \texttt{last\_sec}\;
%			\If{\texttt{pad\_size} $<$ size of \texttt{code} + size of jump}{
%				Print error message and exit\;
%			}
%			Inject the payload \texttt{code} into the padding space\;
%			Generate a jump instruction \texttt{jmp\_back} to the original entry point\;
%			Inject \texttt{jmp\_back} after the \texttt{code}\;
%			Modify the section header of \texttt{last\_sec} to extend its size\;
%			Update the \texttt{phdr}'s file and memory size to include the injected code\;
%			Update the ELF header's \texttt{e\_entry} to point to the start of the payload \texttt{code}\;
%			\textbf{break}\;
%		}
%	}
%	Write the modified ELF to \texttt{output\_elf}\;
%	Set the file permission of \texttt{output\_elf} to executable\;
%\end{algorithm}

%基于时间延迟的动态扰动方法是一种有效的动态对抗技术，具有实现简单、效果明显、通用性强等优点，可作为恶意样本在强化学习训练与对抗生成中的关键扰动操作之一，具体实现如算法1所示。

%The disturbance method based on time delay is an effective dynamic adversarial technique that has advantages in simple implementation, high efficiency, and high versatility. It serves as a key disturbance operation for malware in reinforcement learning training and adversarial generation. Its concrete implementation is described in Algorithm 1 below.

%算法1通过逐步操作，实现将载荷二进制代码动态插入到目标ELF可执行文件的可执行段填充空间中，保持原文件结构的同时实现控制流重定向。第1至2行将目标ELF文件与待插入的payload读入内存。第3至4行验证ELF文件的合法性，包括magic、是否为64位及是否为x86-64架构。第5至17行是注入的核心步骤：遍历每个程序头，第6行判断是否为可执行段（具有PF\_X标志），第7至8行定位该段的最后一个节并计算其后的空隙空间大小；若填充不足以插入payload与跳转指令，则退出（第9至10行）。第11至13行将载荷写入空隙并附加一段跳转回原始入口点的代码。随后，第14至15行扩展节和段的大小字段以覆盖新注入区域，确保在运行时被正确加载。第16行更新ELF头中的入口地址e\_entry为payload的起始位置，实现控制流重定向。完成注入后（第17行），退出循环以防止重复操作。最后，第18至19行将修改后的ELF写入输出文件并设置为可执行。整体流程在不破坏原有功能的前提下，实现了高隐蔽性和完整性兼容的动态插入操作。

%Algorithm 1 operates step-by-step, achieving inserting payload binary code into target ELF executable file's executable segment padding, maintaining original file structure while achieving control flow redirection. Lines 1 to 2 read target ELF file and payload into memory. Lines 3 to 4 check the legitimacy of ELF file, including magic number, whether it is 64 bits, and whether its architecture is x86-64. Lines 5 to 17 is the core process of injection, traversing each program header. Line 6 judges whether the segment is an executable segment that contains the PF\_X flag. Lines 7 to 8 locate the last section of this segment and calculate the gap size after it. Lines 9 to 10 terminate the process when the gap size cannot accommodate the payload and jump instructions. Lines 11 to 13 write the payload to the gap and append code block that jumps to the original entry point. Subsequently, lines 14 to 15 expand the size fields of the section and segment to cover newly injected areas to ensure that it can be loaded correctly during execution. Line 16 updates the entry point e\_entry in the ELF header to be the starting point of payload, achieving control flow redirection. Line 17 exits the loop to prevent duplicate operations after the injection is completed. Finally, lines 18 to 19 write the modified ELF file to an output file and set it as an executable file. The overall process achieves dynamic insertion operations that exhibit high concealment and complete compatibility in the condition that the original functionality is not broken.

\section{动态奖励函数策略优化（DRFOS）Dynamic Reward Function Optimization Strategy (DRFOS)}

%传统对抗样本生成方法多采用固定或静态的奖励函数，往往仅考虑单一的检测规避结果，例如是否成功逃避分类器或沙箱分析系统\cite{anderson2018learning}。然而，在实际应用场景中，恶意样本的行为表征、检测机制、资源限制（如沙箱分析时长）等因素均具备高度动态性。因此，本文设计一种自适应、阶段感知和行为敏感的动态奖励函数策略，对于提升对抗样本生成质量和鲁棒性具有重要意义。

%Traditional adversarial sample generation methods mostly adopt fixed or static reward functions, often considering only a single evasion detection result, such as whether the sample successfully evades a classifier or a sandbox analysis system\cite{anderson2018learning}. However, in real application scenarios, factors such as malware behavioral characteristics, detection mechanisms, and resource constraints, such as sandbox analysis duration, exhibit high dynamism. Therefore, this research designs an adaptive, stage-aware, and behaviorally sensitive dynamic reward function strategy that is significant for improving the quality and robustness of adversarial sample generation.

%本文提出一种动态奖励函数优化策略，结合多个维度的行为表现动态调整奖励函数，以提升样本的逃避能力、生成效率与混淆性。

%This research proposes a dynamic reward function optimization strategy that dynamically adjusts the reward function based on multi-dimensional behavioral performance to enhance evasion capability, generation efficiency, and obfuscation of samples.

%在基于强化学习的对抗恶意样本生成框架中，奖励函数设计是智能体学习策略的核心驱动力。传统对抗样本生成方法多采用固定或静态的奖励函数，往往仅考虑单一的检测规避结果，例如是否成功逃避分类器或沙箱分析系统。然而，在实际应用场景中，恶意样本的行为表征、检测机制、资源限制（如沙箱分析时长）等因素均具备高度动态性。因此，设计一种自适应、阶段感知和行为敏感的动态奖励函数策略，对于提升对抗样本生成质量和鲁棒性具有重要意义。

%In an adversarial malware sample generation framework based on RL, reward function design serves as the core driving force for agent policy learning. Traditional adversarial sample generation methods mostly adopt fixed or static reward functions, often considering only a single evasion detection result, such as whether the sample successfully evades a classifier or a sandbox analysis system. However, in real application scenarios, factors such as malware behavioral characteristics, detection mechanisms, and resource constraints, such as sandbox analysis duration, exhibit high dynamism. Therefore, designing a dynamic reward function strategy that is adaptive and behaviorally sensitive, and has high stage awareness, is crucial for improving the quality and robustness of adversarial sample generation.

%\subsection{奖励函数设计动机 Motivation for Reward Function Design}

%强化学习智能体的行为策略直接受其奖励信号驱动。若奖励仅依据“是否逃避成功”这一单一信号，则智能体可能在初始训练阶段陷入稀疏奖励困境，导致训练效率低下，策略不稳定，甚至难以收敛。为解决该问题，本方法引入多源奖励信号融合机制，综合以下三类指标：

%The behavioral policy of a reinforcement learning agent is directly driven by its reward signals. If rewards are solely based on the singular signal of "whether evasion is successful," the agent may face sparse reward dilemmas during initial training phases, resulting in inefficient training, unstable strategies, or even failure to converge. To address this issue, this research proposes a method that introduces a multi-source reward signal fusion mechanism, integrating the following three metrics:

%规避性得分（Evasion Score）：反映样本是否成功规避沙箱或机器学习检测模型，是核心奖励来源；

%Evasion Score: It reflects whether the sample successfully evades sandbox or machine learning detection models, serving as the primary reward source.

%扰动成本（Perturbation Cost）：衡量修改对原始样本的干扰程度，用于抑制过度修改，保持样本可执行性与语义一致性；

%Perturbation Cost: It measures the perturbation degree of modifications to the original sample, suppressing excessive alterations to maintain executability and semantic consistency.

%行为混淆度（Behavior Confusion Degree）：衡量样本行为与正常软件的相似度，鼓励智能体生成更具隐蔽性的扰动策略。

%Behavior Confusion Degree: It measures the similarity between sample behavior and benign software, encouraging the agent to generate more stealthy disturbance strategies.

%\subsection{奖励函数表达形式 Reward Function Formulation}
 
%定义智能体在时刻 $t$ 执行扰动动作 $a_t$ 后的奖励 $R_t$ 为多项加权组合：

%The reward $R_t$ for the agent after executing disturbance action $a_t$ at time $t$ is defined as a weighted combination:
%\begin{equation}
%	R_t = \lambda_1 \cdot R_{\text{evasion}} + \lambda_2 \cdot R_{\text{confusion}} %- \lambda_3 \cdot R_{\text{cost}}
%\end{equation}

%其中，$R_{\text{evasion}}$ 表示若样本成功绕过沙箱或分类器则给予正奖励，否则为 0；$R_{\text{confusion}}$ 表示根据行为序列（如系统调用图）与良性样本的相似度计算得分，例如使用 Jaccard 相似度或结构相似性；$R_{\text{cost}}$ 表示扰动的代价，可以根据扰动次数、修改字节数以及修改位置的敏感度等进行计算；$\lambda_1$、$\lambda_2$ 和 $\lambda_3$ 为动态可调的权重参数。

%In this formulation, $R_{\text{evasion}}$ represents that if the sample evade the sandbox or classifier, positive reward should be given, otherwise, the reward is zero; $R_{\text{confusion}}$ represents a score calculated from the similarity between behavioral sequence, such as system call graphs, and benign samples, such as using Jaccard similarity or structural similarity; $R_{\text{cost}}$ denotes the disturbance cost that is calculated based on number of disturbances, modified bytes, and sensitivity of modified locations; $\lambda_1$, $\lambda_2$, and $\lambda_3$ are dynamically adjustable weighting parameters.

\section{基于LSTM的PPO时序模型结构 PPO Sequential Model Structure Based on LSTM}

%本章提出的基于PPO（Proximal Policy Optimization）与 LSTM（Long Short-Term Memory）结合的强化学习模型主要由四个部分组成：LSTM时间特征编码层、策略网络（Actor）、价值网络（Critic）以及PPO优化器。训练过程中，首先由策略网络根据当前环境状态生成动作概率分布，同时价值网络对当前状态进行价值评估。为了能够有效建模动作序列中的时间依赖性，引入了LSTM模块，使得模型能够记忆过去的历史状态信息，捕获长期依赖特征，从而提升策略的稳定性与鲁棒性。最后，通过PPO优化器对策略进行迭代更新，保证训练过程中策略更新的稳定性与高效性。

%The reinforcement learning model combining PPO and LSTM, proposed in this chapter, consists of four main components: an LSTM temporal feature encoding layer, a policy network (Actor), a value network (Critic), and a PPO optimizer. During the training process, first, the policy network generates an action probability distribution based on the current environment state. Concurrently, the value network evaluates the value of the current state. To effectively model temporal dependencies in action sequences, the LSTM module is introduced, which enables the model to record historical state information and capture long-term dependency features, enhancing policy stability and robustness. Finally, the PPO optimizer iteratively updates the policy, ensuring stable and efficient policy updates throughout the training process.

%\begin{algorithm}[htbp]
%	\caption{基于强化学习的 ELF 对抗样本生成算法}
%	\KwIn{原始 ELF 恶意样本集 $S$，最大迭代次数 $I$，预训练模型 $M$（PPO+LSTM），免杀行为表 \texttt{Action\_table}，检测结果记录表 \texttt{Re}}
%	\KwOut{免杀后的样本集 $S$}
%	初始化智能体 agent 与环境 env\;
%	agent $\leftarrow$ PPO\_LSTM.load($M$)\;
%	$R_d \leftarrow 0$\;
%	\ForEach{$s \in S$}{
%		env.reset()\;
%		tag $\leftarrow$ env.detect($s$)\;
%		$S_t \leftarrow [\ ]$\;
%		\For{$i \leftarrow 1$ \KwTo $9$}{
%			$S_t \leftarrow S_t + \texttt{env.extractor}(s, i)$\;
%		}
%		\For{$j \leftarrow 1$ \KwTo $I$}{
%			act $\leftarrow$ agent.predict($S_t$, $R_d$)\;
%			\If{tag == benign}{
%				\textbf{break}\;
%			}
%			$s \leftarrow \texttt{env.step}(s, \texttt{Action\_table}[act])$\;
%			$S_t \leftarrow [\ ]$\;
%			\For{$i \leftarrow 1$ \KwTo $9$}{
%				$S_t \leftarrow S_t + \texttt{env.extractor}(s, i)$\;
%			}
%			tag $\leftarrow$ env.detect($s$)\;
%			
%			计算规避性得分：\texttt{Evasion\_Score} $\leftarrow$ score\_function($s$)\;
			
%			计算行为混淆度：\texttt{Behavior\_Confusion\_Degree} $\leftarrow$ calculate\_confusion\_degree($s$)\;
			
%			计算扰动成本：\texttt{Perturbation\_Cost} $\leftarrow$ calculate\_perturbation\_cost($s$, \texttt{Action\_table}[act])\;
			
%			\If{tag == benign}{
%				$R_d \leftarrow 10 \cdot \texttt{coefficient1} + \texttt{Behavior\_Confusion\_Degree} - \texttt{Perturbation\_Cost}$\;
%				\textbf{break}\;
%			}
%			\Else{
%				$R_d \leftarrow \texttt{Behavior\_Confusion\_Degree} - \texttt{Perturbation\_Cost}$\;
%			}
%		}
%		\texttt{Re[$s$]} $\leftarrow$ tag\;
%	}
%\end{algorithm}

%算法2描述了通过强化学习（PPO+LSTM）模型生成ELF格式恶意样本的免杀对抗样本。第1至2行初始化智能体和环境，加载预训练的PPO+LSTM模型。第3行初始化奖励信号$R_d$为0。第4至6行遍历原始恶意样本集$S$并重置环境，检测样本的标签。第7至9行提取环境中的特征，并存储在状态$S_t$中。第10至26行是主要的扰动步骤：智能体根据当前状态和奖励预测执行动作。第11至12行通过智能体的预测生成扰动动作，并根据样本标签（恶意或良性）决定是否继续执行。第13至15行，执行动作后更新样本并提取新的环境特征。第16至18行，计算新的奖励值，综合考虑规避性得分、行为混淆度和扰动成本。第19至24行根据检测结果和扰动成本动态计算奖励值，如果样本成功规避检测则给予较高的奖励，否则计算扰动成本并适当降低奖励。第27行更新样本的标签并记录在检测结果表Re中。整个流程通过多源奖励信号的融合与动态调整，逐步优化智能体的策略，以生成能够有效绕过检测并保持样本可执行性的对抗样本。

%Algorithm 2 describes the ELF-format malware adversarial sample generation process that uses a reinforcement learning model based on PPO and LSTM. Lines 1 to 2 initialize the agent and environment, loading the pre-trained PPO+LSTM model. Line 3 initializes the reward signal $R_d$ to 0. Lines 4 to 6 iterate through the original malicious sample set $S$, reset the environment, and detect the sample's label. Lines 7 to 9 extract features from the environment and store them in state $S_t$. Lines 10 to 26 are the core disturbance steps: the agent predicts an action based on the current state and reward signal. Lines 11 to 12 generate disturbance actions based on the agent's prediction and decide whether to continue according to whether the sample's label is benign or malicious. After executing actions, lines 13 to 15 update samples and extract novel environmental characteristics. Line 16 to 18 calculate novel reward value comprehensively based on evasion score, behavior confusion degree, and disturbance cost. Line 19 to 24 dynamically calculates reward values according to the detection result and disturbance cost. If the sample evades detection successfully, higher rewards will be granted. Otherwise, the disturbance cost is calculated, and rewards are penalized. Line 27 updates the sample's label and records it in the result table Re. The whole process gradually optimizes the agent's strategies through merging multi-source signals and adjusting dynamically, generating adversarial samples that evade detection effectively while maintaining executability.

%\subsection{LSTM时间特征编码层 LSTM Temporal Feature Encoding Layer}

%在传统强化学习中，策略与价值估计往往只基于当前状态单步决策，忽略了历史决策之间的时间关联性，容易导致短视行为。

%In traditional RL, policy and value estimation usually rely solely on single-step decisions based on the current state, neglecting temporal correlations among historical decisions. This can lead to short-sighted behavior.

%为此，本模型在输入端引入了LSTM（长短期记忆网络），通过门控机制捕获长期依赖，增强决策的时序连贯性。

%To address this issue, the model introduces an LSTM layer at the input stage. Through gating mechanisms, LSTM captures long-term dependencies, enhancing the temporal coherence of decision-making.

%LSTM单元内部操作公式如下：

%Internal operation formulations of the LSTM unit are defined as follows:

%输入门（控制当前输入信息的流入）：

%Input Gate (controlling the flow of current input information):
%\begin{equation}
%i_t = \sigma(W_i x_t + U_i h_{t-1} + b_i)
%\end{equation}

%遗忘门（控制上一个记忆单元的保留程度）：

%Forget Gate (controlling retention level of the previous memory cell):
%\begin{equation}
%f_t = \sigma(W_f x_t + U_f h_{t-1} + b_f)
%\end{equation}

%单元状态更新（生成新的记忆内容）：

%Cell State Update (Generating new memory content):
%\begin{equation}
%\tilde{c}_t = \tanh(W_c x_t + U_c h_{t-1} + b_c)
%\end{equation}

%单元状态（记忆细胞）更新：

%Cell State Update (memory cell):
%\begin{equation}
%c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t
%\end{equation}

%输出门（控制隐藏状态输出）：

%Output Gate (controlling hidden state output):
%\begin{equation}
%o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o)
%\end{equation}

%隐藏状态更新（作为下一步输出）：

%Hidden State Update (output for the next step):
%\begin{equation}
%h_t = o_t \odot \tanh(c_t)
%\end{equation}

%其中，$\sigma$ 为 Sigmoid 激活函数，$\odot$ 表示 Hadamard 乘积（元素乘），
%$x_t$ 是当前时刻的输入状态，$h_{t-1}$ 和 $c_{t-1}$ 分别是上一时刻的隐藏状态与单元状态。

%In the formulations, $\sigma$ is the Sigmoid activation function. $\odot$ represents the Hadamard product in element multiplication. $x_t$ is the input state of current time. $h_{t-1}$ and $c_{t-1}$ are the hidden state and cell state of the previous time step.

%通过以上机制，LSTM 能有效捕捉输入状态序列中的长期依赖特征，使策略网络与价值网络具有更强的历史建模能力。

%This mechanism enables the LSTM to effectively capture long-term dependencies in input state sequences, enhancing the historical modeling capability of the policy and value networks.

%\subsection{策略网络（Actor） Policy Network (Actor)}

%策略网络负责从环境中接收到的状态信息中，输出当前动作的概率分布。为了增强策略对于历史信息的感知能力，策略网络在输入端接入了LSTM层，LSTM能够在一定程度上记忆先前状态的隐藏信息，从而使得输出的策略不仅依赖当前时刻的观测，还综合考虑了历史观测序列的特征。
%策略网络的目标是根据当前的隐藏状态$h_{t}$，输出每个动作的概率分布$\pi_{\theta}(a_{t}|s_{t})$ 。
%具体过程如下：

%The policy network receives environmental state information and outputs the probability distribution of current actions. To enhance its awareness of historical information, the policy network introduces an LSTM layer at the input stage. The LSTM records hidden information from previous states, enabling the output policy to rely on not only the current observation but also features from historical observation sequences. The policy network's goal is to output each action's probability distribution $\pi_{\theta}(a_{t}|s_{t})$ based on the current hidden state $h_{t}$. The concrete processes are listed below:

%\begin{enumerate} [label=\arabic*)] 

%\item LSTM编码后的隐藏状态$h_{t}$作为输入;

%The LSTM-encoded hidden state $h_{t}$ serves as input.

%\item 经过多层感知机（MLP）映射至动作空间;

%A multilayer perceptron (MLP) maps this to the action space.

%\item 通过 Softmax 函数输出动作分布：

%The Softmax function outputs the action distribution:
%\begin{equation}
%\pi_{\theta}(a_t | s_t) = Softmax(W_p h_t + b_p)
%\tag{4.8}
%\end{equation}
%其中，$W_p$、$b_p$ 为策略网络的权重与偏置参数，$\theta$ 表示策略网络的参数集合;

%In this formulation, $W_p$ and $b_p$ are the policy network's weight and bias parameters, and $\theta$ represents the policy network's parameter set.

%\item 依据动作概率分布进行采样，生成动作 $a_t$：

%Actions $a_t$ are generated according to the sampling from the probability distribution.
%\begin{equation}
%a_t \sim \pi_\theta(a_t | s_t)
%\end{equation}

%\end{enumerate}

%\subsection{价值网络（Critic） Value Network (Critic)}

%价值网络负责对当前状态的价值进行估计，即预测从当前状态出发，在未来遵循当前策略所能获得的期望回报。与策略网络类似，价值网络同样引入了LSTM编码层，以捕获状态序列中的时间关联性，提升价值估计的准确性和稳定性。

%The value network estimates the value of the current state and predicts the expected cumulative reward obtained by following the current policy starting from the current state. Like the policy network, the value network introduces an LSTM encoding layer to capture temporal correlations in state sequences, enhancing estimation accuracy and stability.

%价值网络旨在估计当前状态$s_{t}$的状态价值函数$V^{\pi}(s_{t})$，即从状态$s_{t}$出发，在未来遵循当前策略$\pi$所能获得的期望总回报。与策略网络结构类似，价值网络也基于LSTM编码后的隐藏状态$h_{t}$，经MLP输出一个实数值：

%The value network aims to estimate the state-value function $V^{\pi}(s_{t})$ in current state $s_{t}$, the expected total reward from state $s_t$ following current strategy $\pi$. Like the structure of strategy networks, value networks are also based on the LSTM-encoded hidden state $h_{t}$ and output a scalar value through MLP.

%状态价值估计：

%State value estimation:
%\begin{equation}
%V_{\phi}(s_t) = W_v h_t + b_v
%\end{equation}

%其中，$W_v$ 和 $b_v$ 分别为价值网络的权重与偏置参数，${\phi}$为价值网络参数集合。

%In this formulation, $W_v$ and $b_v$ are the weight and bias parameters of the value network, and $\phi$ denotes its parameter set.

%\subsection{策略优化器 Policy Optimizer}

%PPO 引入了剪切（Clipped）目标函数，在更新策略时，限制新旧策略之间的变动范围，从而提高训练的稳定性。

%PPO introduces a clipped objective function that limits the divergence between old and new policies during updates, enhancing training stability.

%首先定义概率比率 \(r_t(\theta)\)：

%First,the probability ratio $r_t(\theta)$ is defined as:
%\begin{equation}
%	r_t(\theta) = \frac{\pi_{\theta}(a_t | s_t)}{\pi_{\theta_{\text{old}}}(a_t | s_t)} \tag{4.11}
%\end{equation}

%其中，\(\pi_{\theta_{\text{old}}}\) 表示上一次更新前的策略参数。

%$\pi_{\theta_{\text{old}}}$ represents the pre-update policy parameters.

%优势函数（Advantage）定义为：

%The advantage function $A_t$ is defined as:
%\begin{equation}
%	A_t = \delta_t = r_t + \gamma V(s_{t+1}) - V(s_t) \tag{4.12}
%\end{equation}

%其中，\(r_t\) 为即时奖励，\(\gamma\) 为折扣因子。

%$r_t$ is the immediate reward and $\gamma$ is the discount factor.

%PPO 的最终优化目标为：

%PPO's ultimate optimization target is:
%\begin{equation}
%	L^{\text{CLIP}}(\theta) = \mathbb{E}_t \left[ \min \left( r_t(\theta) A_t, \ \text{clip}\big(r_t(\theta), 1-\epsilon, 1+\epsilon\big) A_t \right) \right] \tag{4.13}
%\end{equation}

%当 \(r_t(\theta)\) 处于 \((1-\epsilon, 1+\epsilon)\) 区间内时，直接使用真实比率乘以优势函数；当超出该区间时，使用裁剪后的比率，防止策略更新幅度过大。

%When \(r_t(\theta)\) lies in the range \((1-\epsilon, 1+\epsilon)\), the true ratio multiplied by the advantage function is used. Outside this range, the clipped ratio is used to prevent excessive policy updates.

%价值函数损失（均方误差）为：

%The value function loss (squared error) is:
%\begin{equation}
%	L^{\text{VF}}(\varphi) = \mathbb{E}_t \left[ \left(V_{\varphi}(s_t) - R_t\right)^2 \right] \tag{4.14}
%\end{equation}

%其中，\(R_t\) 是累积回报（真实价值目标）。

%In this formulation, $R_t$ is the cumulative return (real value target).

%最终的整体损失函数（综合考虑策略损失、价值损失和熵正则化）为：

%The ultimate overall loss function combining policy loss, value loss, and entropy regularization is:
%\begin{equation}
%	L(\theta, \varphi) = L^{\text{CLIP}}(\theta) - c_1 L^{\text{VF}}(\varphi) + c_2 S[\pi_{\theta}] \tag{4.15}
%\end{equation}

%其中，\(S[\pi_{\theta}]\) 为策略熵，用以鼓励探索；\(c_1\) 和 \(c_2\) 为损失权重系数。

%Where \(S[\pi_{\theta}]\) is the policy entropy to encourage exploration. \(c_1\) %and \(c_2\) are weighting coefficients.


%\section{本章小结 Chapter Summary}

%本章介绍了基于强化学习的恶意软件对抗样本生成技术，重点阐述了如何利用强化学习与多种扰动方法相结合，生成能够有效规避恶意软件检测模型的对抗样本。介绍了利用强化学习优化扰动策略的方式，使生成的恶意软件样本在保证隐蔽性的同时，能够有效规避多个检测模型的识别。接着介绍了本章所提出的奖励函数优化方案，以及详细介绍了提出的基于LSTM的PPO时序模型的具体实现。

%This chapter introduces adversarial malware sample generation techniques based on RL. It details how RL combines multiple disturbance methods to generate adversarial samples capable of evading malware detection models. The method for optimizing disturbance strategies via RL is explained, demonstrating how to generate malware samples that maintain concealment while evading detection by multiple models. Then this chapter presents the reward function optimization strategy and thoroughly describes the implementation of the PPO sequential model based on LSTM.




